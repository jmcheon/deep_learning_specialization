# Course2 - Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization

In course 2 on the practical aspects of deep learning, you'll learn how to make your neural networks work well. Ranging from hyperparameter tuning to how to set up your data set, to how to make sure your optimization algorithm runs quickly so that you get your learning algorithm to learn in a reasonable amount of time.

### Table of Contents

  - [Module1 - Practical Aspects of Deep Learning](https://github.com/jmcheon/deep_learning_specialization/tree/main/Course2/Module1)
  - [Module2 - Optimization Algorithms](https://github.com/jmcheon/deep_learning_specialization/tree/main/Course2/Module2)
  - [Module3 - Hyperparameter Tuning, Batch Normalization and Programming Frameworks](https://github.com/jmcheon/deep_learning_specialization/tree/main/Course2/Module3)
<br/>


## Module1 - Practical Aspects of Deep Learning
Discover and experiment with a variety of different initialization methods, apply L2 regularization and dropout to avoid model overfitting, then apply gradient checking to identify errors in a fraud detection model.

- Setting up your Machine Learning Application
- Regularizing your Neural Network
- Setting up your Optimization Problem



## Module2 -  Optimization Algorithms
Develop your deep learning toolbox by adding more advanced optimizations, random minibatching and learning rate decay scheduling to speed up your model.

- Optimization Algorithms

## Module3 - Hyperparameter Tuning, Batch Normalization and Programming Frameworks
Explore Tenserflow, a deep learning framework that allows you to build neural networks quickly and easily, then train a neural network on a Tensorflow dataset.

- Hyperparameter Tuning
- Batch Normalization
- Multi-class Classification
- Introdunction to Programming Frameworks